{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88888ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.9870, Train Acc: 66.91%, Val Loss: 0.8043, Val Acc: 73.00%, Precision: 0.7316, Recall: 0.7330, F1-score: 0.7268\n",
      "Confusion Matrix:\n",
      "[[351  16  14  16   7   2   4   3  30  33]\n",
      " [  7 427   0   2   2   0   2   1  14  32]\n",
      " [ 37   6 347  12  30  27  44  10   9   5]\n",
      " [  5  10  25 209  23 156  65   6  13  11]\n",
      " [  7   2  21  21 363  17  34  15   2   4]\n",
      " [  1   7 103  32  25 292  17  18   2   7]\n",
      " [  1   5  17   6   8  10 433   1   3   1]\n",
      " [ 14   2  17  23  35  34   5 354   6  19]\n",
      " [ 26  14   6   0   0   1   3   0 441  12]\n",
      " [  3  32   2   4   2   1  10   0  13 433]]\n",
      "Epoch 2: Train Loss: 0.6798, Train Acc: 77.36%, Val Loss: 0.8123, Val Acc: 72.68%, Precision: 0.7495, Recall: 0.7279, F1-score: 0.7223\n",
      "Confusion Matrix:\n",
      "[[415   7  25   6   2   2   1   8   9   1]\n",
      " [ 27 406   8   2   2   2  12   4  22   2]\n",
      " [ 36   0 422  20   7   5  24  10   2   1]\n",
      " [ 22   1  45 330  19  26  36  38   5   1]\n",
      " [ 20   1  68  16 315   7  15  41   3   0]\n",
      " [  6   2  62 156  20 183  23  51   1   0]\n",
      " [  7   0  41  10  14   0 407   4   2   0]\n",
      " [ 14   2  22   9  10   9   3 436   3   1]\n",
      " [ 47   4  14   4   1   1   5   3 421   3]\n",
      " [ 45  74   7   5   7   6  18  22  17 299]]\n",
      "Epoch 3: Train Loss: 0.5470, Train Acc: 81.51%, Val Loss: 0.6180, Val Acc: 79.00%, Precision: 0.7917, Recall: 0.7928, F1-score: 0.7862\n",
      "Confusion Matrix:\n",
      "[[411   8   5   3   5   1   3   6  28   6]\n",
      " [ 15 449   0   1   0   1   1   2   6  12]\n",
      " [ 53   6 370   8  20  14  31  20   4   1]\n",
      " [ 20   8  33 254  36  69  48  39   8   8]\n",
      " [ 16   2  17   4 396   7  11  29   2   2]\n",
      " [  5   6  26  50  29 333  22  30   3   0]\n",
      " [  8   3  15   4  15   0 430   5   4   1]\n",
      " [ 14   3   6   4  17   6   2 450   5   2]\n",
      " [ 26  12   1   2   1   1   1   0 453   6]\n",
      " [ 19  44   1   3   2   0   2   6  19 404]]\n",
      "Epoch 4: Train Loss: 0.4590, Train Acc: 84.66%, Val Loss: 0.6321, Val Acc: 79.16%, Precision: 0.7983, Recall: 0.7935, F1-score: 0.7932\n",
      "Confusion Matrix:\n",
      "[[423   8  11   9   5   2   0   2   9   7]\n",
      " [ 12 447   5   3   1   3   1   0   2  13]\n",
      " [ 38   4 381  21  18  31  25   7   1   1]\n",
      " [ 15   3  17 348  27  63  38   8   0   4]\n",
      " [ 10   0  21  15 390  15   4  27   2   2]\n",
      " [  2   1  11  88  20 357  10  12   0   3]\n",
      " [  9   1  20  16  27   9 401   1   1   0]\n",
      " [ 10   2   8  20  18  30   2 410   1   8]\n",
      " [ 64  14   6   5   1   2   2   0 390  19]\n",
      " [ 18  58   2   3   3   0   1   1   3 411]]\n",
      "Epoch 5: Train Loss: 0.4016, Train Acc: 86.40%, Val Loss: 0.8922, Val Acc: 76.78%, Precision: 0.7889, Recall: 0.7693, F1-score: 0.7705\n",
      "Confusion Matrix:\n",
      "[[385  11  17  12   2   2   1   1  37   8]\n",
      " [  5 442   2   5   1   6   0   1  18   7]\n",
      " [ 31   1 351  60  20  20  25   5  13   1]\n",
      " [  9   3   8 409  25  50   8   2   6   3]\n",
      " [  6   3  14  28 397  11   7  14   5   1]\n",
      " [  3   2  12 253  19 199   1  13   1   1]\n",
      " [  4   2  16  45  18   8 385   1   5   1]\n",
      " [  9   1  12  37  29  29   1 383   5   3]\n",
      " [  8   5   2   3   1   3   0   0 477   4]\n",
      " [  8  38   2   6   2   3   2   2  26 411]]\n",
      "Test Accuracy: 76.94%\n",
      "Test Precision: 0.7942\n",
      "Test Recall: 0.7694\n",
      "Test F1-score: 0.7720\n",
      "Test Confusion Matrix:\n",
      "[[820  16  38  21  12   4   3   2  70  14]\n",
      " [ 14 901   3   8   3   4   1   1  32  33]\n",
      " [ 40   1 691 127  53  47  25   4  10   2]\n",
      " [ 13   7  14 786  45  88  18   9  18   2]\n",
      " [ 14   1  24  69 827  14  17  22  11   1]\n",
      " [  6   3  24 526  31 377  10  12  10   1]\n",
      " [  6   5  20 117  27  21 787   1  15   1]\n",
      " [ 16   0  24  70  51  66   3 755   8   7]\n",
      " [ 23  15   7  15   4   2   2   1 928   3]\n",
      " [ 17  68   9  19   1   6   4   3  51 822]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# 数据预处理操作，针对CIFAR10彩色图像数据集进行归一化等处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# 加载CIFAR10训练集，设置合适参数，CIFAR10的train参数为True表示加载训练集部分\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                         download=True, transform=transform)\n",
    "# 加载CIFAR10测试集，train参数为False表示加载测试集部分\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "# 划分训练集和验证集，采用常见的80%训练集，20%验证集的划分方式\n",
    "train_data, val_data = train_test_split(trainset, test_size=0.1, random_state=42)\n",
    "\n",
    "# 创建训练集数据加载器，设置合理的参数，如batch_size、是否打乱数据以及使用多进程加载数据（num_workers设为合适值）\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64,\n",
    "                                           shuffle=True, num_workers=2)\n",
    "# 创建验证集数据加载器\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "# 创建测试集数据加载器\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "# 实例化预训练的ResNet18模型，CIFAR10是彩色图像，其输入通道数符合ResNet18默认的3通道输入要求，无需修改conv1层\n",
    "model = resnet18(pretrained=True)\n",
    "# 根据CIFAR10数据集的类别数量（10类）调整全连接层输出维度\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 定义损失函数，依然采用交叉熵损失函数用于多分类任务\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 定义优化器，使用Adam优化器，学习率可后续根据实际情况进一步优化调整\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    val_loss = running_loss / len(val_loader)\n",
    "    val_acc = 100. * correct / total\n",
    "    precision = precision_score(all_targets, all_preds, average='macro')\n",
    "    recall = recall_score(all_targets, all_preds, average='macro')\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "    conf_matrix = confusion_matrix(all_targets, all_preds)\n",
    "    return val_loss, val_acc, precision, recall, f1, conf_matrix\n",
    "\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    test_acc = 100. * correct / total\n",
    "    precision = precision_score(all_targets, all_preds, average='macro')\n",
    "    recall = recall_score(all_targets, all_preds, average='macro')\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "    conf_matrix = confusion_matrix(all_targets, all_preds)\n",
    "    return test_acc, precision, recall, f1, conf_matrix\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, precision, recall, f1, conf_matrix = validate(model, val_loader, criterion, device)\n",
    "    print(f'Epoch {epoch + 1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, '\n",
    "          f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}')\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "test_acc, precision, recall, f1, conf_matrix = test(model, test_loader, device)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1-score: {f1:.4f}\")\n",
    "print(\"Test Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a5ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
