{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "011d53f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.6770, Train Acc: 78.84%, Val Loss: 0.4527, Val Acc: 85.80%, Precision: 0.8561, Recall: 0.8522, F1-score: 0.8484\n",
      "Confusion Matrix:\n",
      "[[1999   72    9   10   21    7   46   11   20  222]\n",
      " [  32 6344   21   44  291   38   16   61   42   30]\n",
      " [  13  146 4696   87   53   28    6   72   51  180]\n",
      " [   4  167   19 2964   51  352   17   15  399  239]\n",
      " [   4  108   24   11 3404   13   10    6   23   56]\n",
      " [   2   32    6   83   37 3174   21    1   21   55]\n",
      " [  40   48    7   25   55  421 2158    4   90   37]\n",
      " [   9  190   72   54   23   17    6 2490   12   21]\n",
      " [  26   58   10   25   26   83   66    2 2042  202]\n",
      " [  12   28   15   22   20   33    5   12   20 2157]]\n",
      "Epoch 2: Train Loss: 0.3699, Train Acc: 89.30%, Val Loss: 0.3641, Val Acc: 89.19%, Precision: 0.9002, Recall: 0.8778, F1-score: 0.8866\n",
      "Confusion Matrix:\n",
      "[[2083  155   11   14   25    3   43   26    6   51]\n",
      " [  12 6681   33   30   42   10    9   90    3    9]\n",
      " [   9   90 4882   26   56   11   11  210    1   36]\n",
      " [  11  234   60 3692   32   72   27   42   20   37]\n",
      " [   3  244   31   15 3332    4    7   13    4    6]\n",
      " [   1   55   11  266   21 2911  144    3    2   18]\n",
      " [  43   70   15   52   42   82 2556    7   13    5]\n",
      " [   2  156   36   18   12    8    0 2658    1    3]\n",
      " [  33  124   49  111   31   40  176   17 1877   82]\n",
      " [  24   78   53   39   67   39    8   14    4 1998]]\n",
      "Epoch 3: Train Loss: 0.3035, Train Acc: 91.22%, Val Loss: 0.3173, Val Acc: 90.31%, Precision: 0.8975, Recall: 0.8944, F1-score: 0.8938\n",
      "Confusion Matrix:\n",
      "[[2217   64    6    9   17    2    2   17   34   49]\n",
      " [  36 6497   48   61  103   26    3  113   20   12]\n",
      " [  27   40 5002   37   61   14    2   84   24   41]\n",
      " [   9   69   52 3732   45  161    9   60   63   27]\n",
      " [  11   98   26   13 3458   16    0   11   16   10]\n",
      " [   5   24   10  160   22 3121   38   13   29   10]\n",
      " [ 185   34   13   49   64  138 2089    6  292   15]\n",
      " [   6   88   57   20   14    9    1 2683    7    9]\n",
      " [  29   41   11   64   43   35   10   10 2235   62]\n",
      " [  38   22   33   37   47   54    4   13   29 2047]]\n",
      "Epoch 4: Train Loss: 0.2569, Train Acc: 92.68%, Val Loss: 0.3020, Val Acc: 91.14%, Precision: 0.9141, Recall: 0.9027, F1-score: 0.9074\n",
      "Confusion Matrix:\n",
      "[[2198  113   17    7    8    0   13    9   27   25]\n",
      " [  18 6654   65   24   47   16    5   61   25    4]\n",
      " [  12   59 5098   29   28   13    4   30   40   19]\n",
      " [  17  164   69 3547   15  144   17   29  199   26]\n",
      " [   5  150   42   10 3373   11    8   21   26   13]\n",
      " [   1   47   12  118   10 3112   65    4   50   13]\n",
      " [  50   66   19   19   53   73 2492    1  105    7]\n",
      " [   3  153   84   15    4    5    0 2619    3    8]\n",
      " [  20   70   43   13   12   24   46    7 2282   23]\n",
      " [  48   56   51   16   20   35    5   11   72 2010]]\n",
      "Epoch 5: Train Loss: 0.2121, Train Acc: 93.90%, Val Loss: 0.2883, Val Acc: 91.72%, Precision: 0.9155, Recall: 0.9090, F1-score: 0.9117\n",
      "Confusion Matrix:\n",
      "[[2165   76    9    8   19    6   89   10   15   20]\n",
      " [  39 6604   37   42   66   22   12   82    9    6]\n",
      " [  25   62 4999   31   32   15    9  123   10   26]\n",
      " [  19   74   76 3752   22  131   52   29   49   23]\n",
      " [   8  115   25   22 3433   13    7   14    7   15]\n",
      " [   3   24   11  139    9 3170   51    5    9   11]\n",
      " [  26   34   11   15   54  119 2594    5   23    4]\n",
      " [  11   97   34   19   12   11    2 2701    0    7]\n",
      " [  29   54   34   38   18   33  189    8 2116   21]\n",
      " [  54   28   40   34   20   44   11   14   18 2061]]\n",
      "Test Loss: 0.3033, Test Acc: 91.37%, Precision: 0.9066, Recall: 0.9019, F1-score: 0.9022\n",
      "Confusion Matrix:\n",
      "[[1576   19    7   11    5    6   95    9    4   12]\n",
      " [  28 4904   21   17   47   16   10   52    2    2]\n",
      " [  13   42 3903   21   20   21   12  101    2   14]\n",
      " [  14   64   63 2427   12   72   40   15   48  127]\n",
      " [  14   56   19   10 2396    8    6   10    1    3]\n",
      " [   6   13   15   71   10 2194   48   12    3   12]\n",
      " [  22   14    4    6   23   58 1835    9    3    3]\n",
      " [   6   75   11    9    3    7    3 1904    0    1]\n",
      " [  20   12   22   35   20   29  257    6 1231   28]\n",
      " [  55   14   38   10    8   13   11   17   13 1416]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# 数据预处理操作，调整为适合SVHN数据集的归一化参数（示例参数，可根据实际情况优化）\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# 加载SVHN训练集，设置合适的参数\n",
    "trainset = torchvision.datasets.SVHN(root='./data', split='train',\n",
    "                                      download=True, transform=transform)\n",
    "# 加载SVHN测试集\n",
    "testset = torchvision.datasets.SVHN(root='./data', split='test',\n",
    "                                     download=True, transform=transform)\n",
    "\n",
    "# 划分训练集和验证集，这里采用常见的80%训练集，20%验证集划分方式\n",
    "train_data, val_data = train_test_split(trainset, test_size=0.5, random_state=42)\n",
    "\n",
    "# 创建训练集数据加载器，设置合适的参数\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64,\n",
    "                                           shuffle=True, num_workers=2)\n",
    "# 创建验证集数据加载器\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "# 创建测试集数据加载器\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "# 实例化预训练的ResNet18模型\n",
    "model = resnet18(pretrained=True)\n",
    "# SVHN是彩色图像，输入通道数为3，所以这里不用修改conv1层的输入通道数\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)  # 根据SVHN的类别数量调整全连接层输出维度（假设类别数为10，可根据实际调整）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 定义损失函数，依然采用交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 定义优化器，使用Adam优化器，学习率可根据实际情况进一步调整\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    val_loss = running_loss / len(val_loader)\n",
    "    val_acc = 100. * correct / total\n",
    "    precision = precision_score(all_targets, all_preds, average='macro')\n",
    "    recall = recall_score(all_targets, all_preds, average='macro')\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "    conf_matrix = confusion_matrix(all_targets, all_preds)\n",
    "    return val_loss, val_acc, precision, recall, f1, conf_matrix\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, precision, recall, f1, conf_matrix = validate(model, val_loader, criterion, device)\n",
    "    print(f'Epoch {epoch + 1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, '\n",
    "          f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}')\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "test_loss, test_acc, precision, recall, f1, conf_matrix = validate(model, test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%, '\n",
    "      f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}')\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068d9661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
