{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "045391fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.5766, Train Acc: 79.54%, Val Loss: 0.4160, Val Acc: 84.77%, Precision: 0.8520, Recall: 0.8479, F1-score: 0.8440\n",
      "Confusion Matrix:\n",
      "[[2299   19   57  390   21    0  154    0   26    0]\n",
      " [   0 2943    5   60    7    0    7    0    1    0]\n",
      " [  22    1 2601   66  176    0  146    0   22    0]\n",
      " [  17   23   24 2918   19    0   16    0    1    0]\n",
      " [   2    3  462  368 1934    0  247    0   17    0]\n",
      " [   0    1    2    5    3 2739    3  108   16   94]\n",
      " [ 536    5  397  350  168    0 1508    0   42    0]\n",
      " [   0    0    0    0    1   44    0 2681    6  223]\n",
      " [   3    1    9   22   11    3   51    2 2855    4]\n",
      " [   0    0    0    3    1    6    2   60    8 2953]]\n",
      "Epoch 2: Train Loss: 0.3990, Train Acc: 85.61%, Val Loss: 0.3740, Val Acc: 86.25%, Precision: 0.8698, Recall: 0.8630, F1-score: 0.8576\n",
      "Confusion Matrix:\n",
      "[[2691    1   64   71    8    4   73    0   54    0]\n",
      " [   7 2926    4   68   11    0    1    0    6    0]\n",
      " [  44    1 2766   46   86    1   57    0   33    0]\n",
      " [ 145   11    9 2687  122    0   20    0   24    0]\n",
      " [   7    1  772  101 1953    0  164    0   35    0]\n",
      " [   0    0    0    2    0 2897    0   58    5    9]\n",
      " [ 793    2  454  122  151    0 1410    0   74    0]\n",
      " [   0    0    0    0    0   79    0 2815    2   59]\n",
      " [   8    0    9    6    2   11    5    5 2915    0]\n",
      " [   0    0    0    0    0   47    0  164    7 2815]]\n",
      "Epoch 3: Train Loss: 0.3281, Train Acc: 88.10%, Val Loss: 0.3059, Val Acc: 88.96%, Precision: 0.8897, Recall: 0.8899, F1-score: 0.8882\n",
      "Confusion Matrix:\n",
      "[[2676    4   70   53    4    0  143    0   16    0]\n",
      " [   6 2969    2   34    3    0    7    0    1    1]\n",
      " [  26    3 2569   23  241    0  169    0    3    0]\n",
      " [  92   33   12 2751   71    0   53    0    5    1]\n",
      " [   4   12  257  126 2473    0  157    0    4    0]\n",
      " [   0    0    0    1    0 2797    0  139    7   27]\n",
      " [ 665    7  242   70  221    0 1796    0    5    0]\n",
      " [   0    0    0    0    0   20    0 2850    5   80]\n",
      " [   4    3   13    8    9    0   37    4 2882    1]\n",
      " [   0    0    0    0    0    6    0   95    6 2926]]\n",
      "Epoch 4: Train Loss: 0.3054, Train Acc: 88.76%, Val Loss: 0.2954, Val Acc: 89.15%, Precision: 0.8965, Recall: 0.8917, F1-score: 0.8923\n",
      "Confusion Matrix:\n",
      "[[2350    9   26   51    4    2  509    0   15    0]\n",
      " [   0 2991    2   22    3    0    4    0    1    0]\n",
      " [  18    3 2517   37  110    1  340    0    8    0]\n",
      " [  77   83    2 2731   48    0   74    0    3    0]\n",
      " [   5   12  347  164 2216    0  280    0    9    0]\n",
      " [   1    1    0    5    0 2860    0   83    1   20]\n",
      " [ 232   11  134   80   93    0 2433    0   23    0]\n",
      " [   0    0    0    0    0   35    0 2849    2   69]\n",
      " [  11    2    4    9    5   14   22    8 2886    0]\n",
      " [   0    0    0    4    0   10    0   99    9 2911]]\n",
      "Epoch 5: Train Loss: 0.2746, Train Acc: 89.86%, Val Loss: 0.3662, Val Acc: 86.58%, Precision: 0.8768, Recall: 0.8663, F1-score: 0.8657\n",
      "Confusion Matrix:\n",
      "[[2742    1   33   42    2    1  134    0   11    0]\n",
      " [  19 2937    1   49    4    1    9    0    2    1]\n",
      " [ 113    0 2584   10   66    0  259    0    2    0]\n",
      " [ 250   12   35 2472   84    2  155    0    7    1]\n",
      " [  38    5  526   32 1790    0  636    0    6    0]\n",
      " [   1    0    0    0    0 2911    0   25    3   31]\n",
      " [ 593    3  174   36   49    1 2141    0    8    1]\n",
      " [   0    0    0    0    0  137    0 2522    3  293]\n",
      " [  21    1   10    4    2    7   27    8 2877    4]\n",
      " [   0    0    0    0    0   15    0   18    1 2999]]\n",
      "Test Accuracy: 86.07%\n",
      "Test Precision: 0.8713\n",
      "Test Recall: 0.8607\n",
      "Test F1-score: 0.8603\n",
      "Test Confusion Matrix:\n",
      "[[915   0   8  13   1   1  57   0   5   0]\n",
      " [  4 972   0  19   2   0   2   0   0   1]\n",
      " [ 43   1 841   3  22   0  90   0   0   0]\n",
      " [ 72   3  13 816  23   0  71   0   2   0]\n",
      " [  6   1 181  12 581   0 218   0   1   0]\n",
      " [  0   0   0   0   0 981   0   9   0  10]\n",
      " [203   1  67  10  27   0 685   0   7   0]\n",
      " [  0   0   0   0   0  46   0 854   1  99]\n",
      " [ 11   1   2   1   1   3   3   2 975   1]\n",
      " [  0   0   0   0   0   4   1   8   0 987]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# 1. 数据预处理部分\n",
    "# FashionMNIST是灰度图像数据集，这里使用适合它的归一化参数进行数据预处理\n",
    "# 将图像转换为张量并进行归一化，有助于提升模型训练效果\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.2860,), (0.3530,))\n",
    "])\n",
    "\n",
    "# 2. 数据集加载部分\n",
    "# 加载FashionMNIST的训练集，设置根目录、表明是训练集、自动下载以及应用数据预处理转换等参数\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
    "                                             download=True, transform=transform)\n",
    "# 加载FashionMNIST的测试集\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "# 3. 数据划分部分\n",
    "# 使用train_test_split将原始训练集划分为新的训练集和验证集，这里采用常见的80%训练集、20%验证集的划分方式\n",
    "# 可以根据实际需求调整test_size参数来改变划分比例\n",
    "train_data, val_data = train_test_split(trainset, test_size=0.5, random_state=42)\n",
    "\n",
    "# 4. 数据加载器创建部分\n",
    "# 创建训练集数据加载器，设置批量大小、打乱数据顺序以及使用多进程加载（num_workers设为合适值可加快加载速度）\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64,\n",
    "                                           shuffle=True, num_workers=2)\n",
    "# 创建验证集数据加载器，不打乱数据顺序\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "# 创建测试集数据加载器，同样不打乱数据顺序\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "# 5. 模型构建与配置部分\n",
    "# 实例化预训练的ResNet18模型，由于FashionMNIST是单通道灰度图像，需修改conv1层的输入通道数为1\n",
    "model = resnet18(pretrained=True)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "# 根据FashionMNIST数据集的类别数量（共10类不同的时尚物品类别）调整全连接层输出维度为10\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 6. 损失函数与优化器定义部分\n",
    "# 定义交叉熵损失函数，用于衡量多分类任务中模型预测结果与真实标签之间的差异\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 定义Adam优化器，并设置初始学习率，学习率可根据后续模型训练情况进一步调整优化\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 7. 训练函数定义部分\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        # 将输入数据和目标数据移动到指定的计算设备（GPU或CPU）上\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# 8. 验证函数定义部分\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    val_loss = running_loss / len(val_loader)\n",
    "    val_acc = 100. * correct / total\n",
    "    precision = precision_score(all_targets, all_preds, average='macro')\n",
    "    recall = recall_score(all_targets, all_preds, average='macro')\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "    conf_matrix = confusion_matrix(all_targets, all_preds)\n",
    "    return val_loss, val_acc, precision, recall, f1, conf_matrix\n",
    "\n",
    "# 9. 测试函数定义部分\n",
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    test_acc = 100. * correct / total\n",
    "    precision = precision_score(all_targets, all_preds, average='macro')\n",
    "    recall = recall_score(all_targets, all_preds, average='macro')\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "    conf_matrix = confusion_matrix(all_targets, all_preds)\n",
    "    return test_acc, precision, recall, f1, conf_matrix\n",
    "\n",
    "# 10. 训练与评估循环部分\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, precision, recall, f1, conf_matrix = validate(model, val_loader, criterion, device)\n",
    "    print(f'Epoch {epoch + 1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, '\n",
    "          f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}')\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "test_acc, precision, recall, f1, conf_matrix = test(model, test_loader, device)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1-score: {f1:.4f}\")\n",
    "print(\"Test Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c3c52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
