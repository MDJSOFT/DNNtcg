{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97a0eaf0-c7cf-4d18-9f5f-1a668fe9bcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 15.56 MiB is free. Process 1582390 has 548.00 MiB memory in use. Process 1590575 has 1.05 GiB memory in use. Process 1666952 has 490.00 MiB memory in use. Process 1671087 has 490.00 MiB memory in use. Process 1687277 has 490.00 MiB memory in use. Process 1718204 has 490.00 MiB memory in use. Process 1760312 has 490.00 MiB memory in use. Process 1815573 has 490.00 MiB memory in use. Process 1848696 has 490.00 MiB memory in use. Process 1870001 has 490.00 MiB memory in use. Process 1920080 has 490.00 MiB memory in use. Process 2073050 has 490.00 MiB memory in use. Process 2125588 has 490.00 MiB memory in use. Process 2857264 has 6.41 GiB memory in use. Process 3103881 has 514.00 MiB memory in use. Process 3224424 has 514.00 MiB memory in use. Process 3317903 has 996.00 MiB memory in use. Process 3341970 has 516.00 MiB memory in use. Process 3409199 has 3.60 GiB memory in use. Process 3426486 has 3.60 GiB memory in use. Process 3435035 has 612.00 MiB memory in use. Of the allocated memory 123.21 MiB is allocated by PyTorch, and 14.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# 训练选择模型\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_selector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_selector\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 训练选择模型\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# 训练预测模型\u001b[39;00m\n\u001b[1;32m     58\u001b[0m train_model(model_predictor, train_loader, optimizer_predictor)  \u001b[38;5;66;03m# 训练预测模型在训练集上\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 50\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, optimizer, epochs)\u001b[0m\n\u001b[1;32m     48\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     49\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 50\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:503\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    495\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    496\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    501\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    502\u001b[0m     )\n\u001b[0;32m--> 503\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:254\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 15.56 MiB is free. Process 1582390 has 548.00 MiB memory in use. Process 1590575 has 1.05 GiB memory in use. Process 1666952 has 490.00 MiB memory in use. Process 1671087 has 490.00 MiB memory in use. Process 1687277 has 490.00 MiB memory in use. Process 1718204 has 490.00 MiB memory in use. Process 1760312 has 490.00 MiB memory in use. Process 1815573 has 490.00 MiB memory in use. Process 1848696 has 490.00 MiB memory in use. Process 1870001 has 490.00 MiB memory in use. Process 1920080 has 490.00 MiB memory in use. Process 2073050 has 490.00 MiB memory in use. Process 2125588 has 490.00 MiB memory in use. Process 2857264 has 6.41 GiB memory in use. Process 3103881 has 514.00 MiB memory in use. Process 3224424 has 514.00 MiB memory in use. Process 3317903 has 996.00 MiB memory in use. Process 3341970 has 516.00 MiB memory in use. Process 3409199 has 3.60 GiB memory in use. Process 3426486 has 3.60 GiB memory in use. Process 3435035 has 612.00 MiB memory in use. Of the allocated memory 123.21 MiB is allocated by PyTorch, and 14.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # CIFAR10的均值和标准差\n",
    "])\n",
    "\n",
    "# 加载CIFAR10数据集\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 定义ResNet18模型\n",
    "def resnet18(pretrained=True):\n",
    "    model = models.resnet18(pretrained=pretrained)\n",
    "    # 修改全连接层以匹配CIFAR10的类别数\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 10)\n",
    "    return model\n",
    "\n",
    "# 实例化两个ResNet18模型\n",
    "model_selector = resnet18(pretrained=True)  # 用于选择最有价值5%测试用例的模型\n",
    "model_predictor = resnet18(pretrained=True)  # 用于对5%测试用例进行预测的模型\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_selector = model_selector.to(device)\n",
    "model_predictor = model_predictor.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_selector = optim.Adam(model_selector.parameters(), lr=0.001)  # 选择模型的优化器\n",
    "optimizer_predictor = optim.Adam(model_predictor.parameters(), lr=0.001)  # 预测模型的优化器\n",
    "\n",
    "# 训练模型\n",
    "def train_model(model, dataloader, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 训练选择模型\n",
    "train_model(model_selector, train_loader, optimizer_selector)  # 训练选择模型\n",
    "\n",
    "# 训练预测模型\n",
    "train_model(model_predictor, train_loader, optimizer_predictor)  # 训练预测模型在训练集上\n",
    "train_model(model_predictor, test_loader, optimizer_predictor)  # 训练预测模型在测试集上\n",
    "\n",
    "# 评估模型并计算置信度\n",
    "model_selector.eval()\n",
    "uncertainties = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        output = model_selector(x)  # 使用选择模型进行评估\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        max_prob, _ = torch.max(probabilities, dim=1)\n",
    "        uncertainties.extend(max_prob.cpu().numpy())\n",
    "        labels.extend(y.cpu().numpy())\n",
    "\n",
    "# 选择最不自信的5%测试用例\n",
    "threshold_index = int(len(uncertainties) * 0.05)\n",
    "threshold = np.partition(uncertainties, -threshold_index)[threshold_index]\n",
    "selected_indices = np.where(uncertainties < threshold)[0]\n",
    "\n",
    "# 使用预测模型对挑选出的测试用例进行预测\n",
    "correct_count = 0\n",
    "total_count = 0\n",
    "with torch.no_grad():\n",
    "    for idx in selected_indices:\n",
    "        img, label = test_dataset[idx]  # 获取图片和标签\n",
    "        img = img.unsqueeze(0).to(device)  # 增加批次维度并移动到设备\n",
    "        output = model_predictor(img)  # 使用预测模型进行预测\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        if predicted.item() == label:\n",
    "            correct_count += 1\n",
    "        total_count += 1\n",
    "\n",
    "# 计算正确分类率\n",
    "accuracy = correct_count / total_count\n",
    "print(f\"正确分类率: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001962c0-908f-49dd-8943-073d752a8941",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.2.0",
   "language": "python",
   "name": "pytorch-2.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
